{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-01-09T07:38:53.666493Z",
     "iopub.status.busy": "2021-01-09T07:38:53.665661Z",
     "iopub.status.idle": "2021-01-09T07:39:00.158009Z",
     "shell.execute_reply": "2021-01-09T07:39:00.158591Z"
    },
    "papermill": {
     "duration": 6.511717,
     "end_time": "2021-01-09T07:39:00.158788",
     "exception": false,
     "start_time": "2021-01-09T07:38:53.647071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf version: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.applications.efficientnet as efn\n",
    "import scipy as sp\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "\n",
    "EFNETS = (efn.EfficientNetB0, efn.EfficientNetB1, efn.EfficientNetB2, efn.EfficientNetB3, \n",
    "          efn.EfficientNetB4, efn.EfficientNetB5, efn.EfficientNetB6, efn.EfficientNetB7)\n",
    "    \n",
    "print(f'tf version: {tf.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-09T07:39:00.187389Z",
     "iopub.status.busy": "2021-01-09T07:39:00.186720Z",
     "iopub.status.idle": "2021-01-09T07:39:12.356171Z",
     "shell.execute_reply": "2021-01-09T07:39:12.355072Z"
    },
    "papermill": {
     "duration": 12.18781,
     "end_time": "2021-01-09T07:39:12.356394",
     "exception": false,
     "start_time": "2021-01-09T07:39:00.168584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_CLASSES = 9\n",
    "SEED = 17\n",
    "IMAGES_DIR = '/kaggle/input/skillbox-emotions/'\n",
    "TEST_DIR = IMAGES_DIR + '/test_kaggle'\n",
    "\n",
    "train_df = pd.read_csv('/kaggle/input/skillbox-computer-vision-project/train.csv').iloc[:, 1:]\n",
    "sub = pd.read_csv('/kaggle/input/skillbox-computer-vision-project/sample_submission.csv')\n",
    "images_test_filenames =  [f for f in os.listdir(TEST_DIR) if isfile(join(TEST_DIR, f))]\n",
    "\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-09T07:39:12.383268Z",
     "iopub.status.busy": "2021-01-09T07:39:12.382205Z",
     "iopub.status.idle": "2021-01-09T07:39:12.385455Z",
     "shell.execute_reply": "2021-01-09T07:39:12.384877Z"
    },
    "papermill": {
     "duration": 0.019618,
     "end_time": "2021-01-09T07:39:12.385569",
     "exception": false,
     "start_time": "2021-01-09T07:39:12.365951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                                    horizontal_flip=True, rotation_range=15, \n",
    "#                                     brightness_range=[0.75, 1.25], \n",
    "                                    width_shift_range=0.15, height_shift_range=0.15)\n",
    "val_data_gen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "test_data_gen = tf.keras.preprocessing.image.ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-09T07:39:12.416221Z",
     "iopub.status.busy": "2021-01-09T07:39:12.415177Z",
     "iopub.status.idle": "2021-01-09T07:41:51.686774Z",
     "shell.execute_reply": "2021-01-09T07:41:51.687600Z"
    },
    "papermill": {
     "duration": 159.292741,
     "end_time": "2021-01-09T07:41:51.687837",
     "exception": false,
     "start_time": "2021-01-09T07:39:12.395096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45041 validated image filenames belonging to 9 classes.\n",
      "Found 5005 validated image filenames belonging to 9 classes.\n",
      "Found 5000 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "EFNET_NO = 0\n",
    "BATCH_SIZE = 128\n",
    "IMSIZES = (224, 240, 260, 300, 380, 456, 528, 600)\n",
    "IMAGE_SIZE = IMSIZES[EFNET_NO]\n",
    "\n",
    "train_data = train_data_gen.flow_from_dataframe(\n",
    "              train_df, directory=IMAGES_DIR, x_col='image_path', y_col='emotion', class_mode='sparse',\n",
    "              target_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE, shuffle=True\n",
    "          )\n",
    "val_data = val_data_gen.flow_from_dataframe(\n",
    "              val_df, directory=IMAGES_DIR, x_col='image_path', y_col='emotion', class_mode='sparse',\n",
    "              target_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE, shuffle=False\n",
    "          )\n",
    "test_data = test_data_gen.flow_from_dataframe(\n",
    "              sub, directory=TEST_DIR, x_col='image_path', y_col=None, class_mode=None,\n",
    "              target_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE, shuffle=False\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-09T07:41:51.721363Z",
     "iopub.status.busy": "2021-01-09T07:41:51.720690Z",
     "iopub.status.idle": "2021-01-09T07:41:59.323040Z",
     "shell.execute_reply": "2021-01-09T07:41:59.323643Z"
    },
    "papermill": {
     "duration": 7.624789,
     "end_time": "2021-01-09T07:41:59.323830",
     "exception": false,
     "start_time": "2021-01-09T07:41:51.699041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "16711680/16705208 [==============================] - 0s 0us/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnetb0 (Functional)  (None, 7, 7, 1280)        4049571   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 9)                 11529     \n",
      "=================================================================\n",
      "Total params: 4,061,100\n",
      "Trainable params: 4,019,077\n",
      "Non-trainable params: 42,023\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    EFNETS[EFNET_NO](\n",
    "        input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "        weights='imagenet',\n",
    "        include_top=False),\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(N_CLASSES, activation='softmax')\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics='accuracy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-09T07:41:59.357335Z",
     "iopub.status.busy": "2021-01-09T07:41:59.356469Z",
     "iopub.status.idle": "2021-01-09T07:41:59.360839Z",
     "shell.execute_reply": "2021-01-09T07:41:59.360242Z"
    },
    "papermill": {
     "duration": 0.023689,
     "end_time": "2021-01-09T07:41:59.360968",
     "exception": false,
     "start_time": "2021-01-09T07:41:59.337279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    'model.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=1)\n",
    "lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_accuracy\", patience=3, min_lr=3e-7, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-09T07:41:59.394976Z",
     "iopub.status.busy": "2021-01-09T07:41:59.394301Z",
     "iopub.status.idle": "2021-01-09T12:47:32.479580Z",
     "shell.execute_reply": "2021-01-09T12:47:32.480465Z"
    },
    "papermill": {
     "duration": 18333.106317,
     "end_time": "2021-01-09T12:47:32.480739",
     "exception": false,
     "start_time": "2021-01-09T07:41:59.374422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "352/352 [==============================] - ETA: 0s - loss: 1.5125 - accuracy: 0.4458\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.48372, saving model to model.h5\n",
      "352/352 [==============================] - 1555s 4s/step - loss: 1.5125 - accuracy: 0.4458 - val_loss: 1.4391 - val_accuracy: 0.4837\n",
      "Epoch 2/15\n",
      "352/352 [==============================] - ETA: 0s - loss: 1.3085 - accuracy: 0.5204\n",
      "Epoch 00002: val_accuracy improved from 0.48372 to 0.49391, saving model to model.h5\n",
      "352/352 [==============================] - 1155s 3s/step - loss: 1.3085 - accuracy: 0.5204 - val_loss: 1.4101 - val_accuracy: 0.4939\n",
      "Epoch 3/15\n",
      "352/352 [==============================] - ETA: 0s - loss: 1.2409 - accuracy: 0.5463\n",
      "Epoch 00003: val_accuracy improved from 0.49391 to 0.52228, saving model to model.h5\n",
      "352/352 [==============================] - 1156s 3s/step - loss: 1.2409 - accuracy: 0.5463 - val_loss: 1.3334 - val_accuracy: 0.5223\n",
      "Epoch 4/15\n",
      "352/352 [==============================] - ETA: 0s - loss: 1.1899 - accuracy: 0.5647\n",
      "Epoch 00004: val_accuracy did not improve from 0.52228\n",
      "352/352 [==============================] - 1122s 3s/step - loss: 1.1899 - accuracy: 0.5647 - val_loss: 1.3680 - val_accuracy: 0.5081\n",
      "Epoch 5/15\n",
      "352/352 [==============================] - ETA: 0s - loss: 1.1415 - accuracy: 0.5838\n",
      "Epoch 00005: val_accuracy did not improve from 0.52228\n",
      "352/352 [==============================] - 1141s 3s/step - loss: 1.1415 - accuracy: 0.5838 - val_loss: 1.3361 - val_accuracy: 0.5215\n",
      "Epoch 6/15\n",
      "352/352 [==============================] - ETA: 0s - loss: 1.0957 - accuracy: 0.6006\n",
      "Epoch 00006: val_accuracy did not improve from 0.52228\n",
      "352/352 [==============================] - 1214s 3s/step - loss: 1.0957 - accuracy: 0.6006 - val_loss: 1.3562 - val_accuracy: 0.5207\n",
      "Epoch 7/15\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.9116 - accuracy: 0.6649\n",
      "Epoch 00007: val_accuracy improved from 0.52228 to 0.55165, saving model to model.h5\n",
      "352/352 [==============================] - 1157s 3s/step - loss: 0.9116 - accuracy: 0.6649 - val_loss: 1.2989 - val_accuracy: 0.5516\n",
      "Epoch 8/15\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.8342 - accuracy: 0.6950\n",
      "Epoch 00008: val_accuracy did not improve from 0.55165\n",
      "352/352 [==============================] - 1184s 3s/step - loss: 0.8342 - accuracy: 0.6950 - val_loss: 1.3301 - val_accuracy: 0.5439\n",
      "Epoch 9/15\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.7830 - accuracy: 0.7119\n",
      "Epoch 00009: val_accuracy did not improve from 0.55165\n",
      "352/352 [==============================] - 1207s 3s/step - loss: 0.7830 - accuracy: 0.7119 - val_loss: 1.3828 - val_accuracy: 0.5431\n",
      "Epoch 10/15\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.7451 - accuracy: 0.7270\n",
      "Epoch 00010: val_accuracy did not improve from 0.55165\n",
      "352/352 [==============================] - 1220s 3s/step - loss: 0.7451 - accuracy: 0.7270 - val_loss: 1.4297 - val_accuracy: 0.5367\n",
      "Epoch 11/15\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.6883 - accuracy: 0.7491\n",
      "Epoch 00011: val_accuracy did not improve from 0.55165\n",
      "352/352 [==============================] - 1215s 3s/step - loss: 0.6883 - accuracy: 0.7491 - val_loss: 1.4450 - val_accuracy: 0.5341\n",
      "Epoch 12/15\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.6850 - accuracy: 0.7494\n",
      "Epoch 00012: val_accuracy did not improve from 0.55165\n",
      "352/352 [==============================] - 1220s 3s/step - loss: 0.6850 - accuracy: 0.7494 - val_loss: 1.4518 - val_accuracy: 0.5369\n",
      "Epoch 13/15\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.6785 - accuracy: 0.7519\n",
      "Epoch 00013: val_accuracy did not improve from 0.55165\n",
      "352/352 [==============================] - 1231s 3s/step - loss: 0.6785 - accuracy: 0.7519 - val_loss: 1.4571 - val_accuracy: 0.5367\n",
      "Epoch 14/15\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.6675 - accuracy: 0.7566\n",
      "Epoch 00014: val_accuracy did not improve from 0.55165\n",
      "352/352 [==============================] - 1234s 4s/step - loss: 0.6675 - accuracy: 0.7566 - val_loss: 1.4596 - val_accuracy: 0.5365\n",
      "Epoch 15/15\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.6730 - accuracy: 0.7526\n",
      "Epoch 00015: val_accuracy did not improve from 0.55165\n",
      "352/352 [==============================] - 1235s 4s/step - loss: 0.6730 - accuracy: 0.7526 - val_loss: 1.4604 - val_accuracy: 0.5355\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data, validation_data=val_data, \n",
    "    epochs=15, callbacks=[checkpoint, lr_reducer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-09T12:47:43.610493Z",
     "iopub.status.busy": "2021-01-09T12:47:43.609423Z",
     "iopub.status.idle": "2021-01-09T12:47:44.253595Z",
     "shell.execute_reply": "2021-01-09T12:47:44.252055Z"
    },
    "papermill": {
     "duration": 6.505517,
     "end_time": "2021-01-09T12:47:44.253791",
     "exception": false,
     "start_time": "2021-01-09T12:47:37.748274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-09T12:47:55.436565Z",
     "iopub.status.busy": "2021-01-09T12:47:55.428904Z",
     "iopub.status.idle": "2021-01-09T12:47:55.437730Z",
     "shell.execute_reply": "2021-01-09T12:47:55.438589Z"
    },
    "papermill": {
     "duration": 5.861143,
     "end_time": "2021-01-09T12:47:55.438816",
     "exception": false,
     "start_time": "2021-01-09T12:47:49.577673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mapping = {k: i for i, k in train_data.class_indices.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-09T12:48:06.619140Z",
     "iopub.status.busy": "2021-01-09T12:48:06.618011Z",
     "iopub.status.idle": "2021-01-09T12:49:49.310967Z",
     "shell.execute_reply": "2021-01-09T12:49:49.309569Z"
    },
    "papermill": {
     "duration": 108.659655,
     "end_time": "2021-01-09T12:49:49.311119",
     "exception": false,
     "start_time": "2021-01-09T12:48:00.651464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_preds = model.predict_classes(test_data)\n",
    "test_preds = [mapping[i] for i in test_preds]\n",
    "sub['emotion'] = test_preds\n",
    "sub.to_csv('preds.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 18663.924001,
   "end_time": "2021-01-09T12:49:52.949038",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-09T07:38:49.025037",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
